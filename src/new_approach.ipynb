{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a062bd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ee/deprecation.py:209: DeprecationWarning: \n",
      "\n",
      "Attention required for JRC/GSW1_0/GlobalSurfaceWater! You are using a deprecated asset.\n",
      "To make sure your code keeps working, please update it.\n",
      "Learn more: https://developers.google.com/earth-engine/datasets/catalog/JRC_GSW1_0_GlobalSurfaceWater\n",
      "\n",
      "  warnings.warn(warning, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/ee/deprecation.py:209: DeprecationWarning: \n",
      "\n",
      "Attention required for MODIS/006/MOD09A1! You are using a deprecated asset.\n",
      "To make sure your code keeps working, please update it.\n",
      "Learn more: https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MOD09A1\n",
      "\n",
      "  warnings.warn(warning, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Core analysis functions - modular and efficient\n",
    "import ee\n",
    "from utils import *\n",
    "# Process geometries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import pyproj\n",
    "\n",
    "# Initialize GEE\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project='dse-staff')\n",
    "\n",
    "# Global datasets\n",
    "PROTECTED_AREAS = ee.FeatureCollection('WCMC/WDPA/current/polygons')\n",
    "ECOREGIONS = ee.FeatureCollection(\"RESOLVE/ECOREGIONS/2017\")\n",
    "WATER_MASK = ee.Image(\"JRC/GSW1_0/GlobalSurfaceWater\").select('max_extent').eq(0)\n",
    "HM_IMAGE = ee.ImageCollection('CSP/HM/GlobalHumanModification').mean()\n",
    "MODIS = ee.ImageCollection('MODIS/006/MOD09A1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8752d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import * \n",
    "def set_geometry_type(feature):\n",
    "    \"\"\"\n",
    "    Sets a 'geometry_type' property on a feature based on its geometry type.\n",
    "    \"\"\"\n",
    "    return feature.set('geometry_type', feature.geometry().type())\n",
    "\n",
    "\n",
    "\n",
    "filtered = filter_protected_areas()\n",
    "\n",
    "filtered_collection = filtered.map(set_geometry_type).filter(\n",
    "    ee.Filter.equals('geometry_type', 'Polygon')\n",
    ")\n",
    "\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=filtered_collection,\n",
    "    description='WDPA_June2021_filtered_wo_perimeter',\n",
    "    fileFormat='SHP'\n",
    ")\n",
    "\n",
    "task.start()\n",
    "\n",
    "#wdpa_pids_ee = filtered_collection.aggregate_array('WDPA_PID')\n",
    "#wdpaids = wdpa_pids_ee.getInfo()\n",
    "#len(wdpaids). #6570"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eae5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6570"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = gpd.read_file('../data/global_wdpa_June2021/WDPA_June2021_filtered_wo_perimeter.shp',encoding='latin1')\n",
    "len(gdf['WDPA_PID'])\n",
    "zones_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d6acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure PA_DEF is numeric (convert to float)\n",
    "gdf[\"PA_DEF\"] = gdf[\"PA_DEF\"].astype(float)\n",
    "# Compute perimeter and perimeter-area ratio\n",
    "gdf[\"PERIMETER\"] = gdf.geometry.length        # length in CRS units\n",
    "gdf[\"PA_RATIO\"]  = gdf[\"PERIMETER\"] / gdf[\"GIS_AREA\"]\n",
    "\n",
    "# Filter: keep only features with PA_RATIO < 75th percentile\n",
    "q75 = gdf[\"PA_RATIO\"].quantile(0.75)\n",
    "gdf_filtered = gdf[gdf[\"PA_RATIO\"] < q75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61337ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827575ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, park in parks_subset.iterrows():\n",
    "    geom = park.geometry\n",
    "    \n",
    "    # Fast local buffer operations\n",
    "    small_ring = geom.buffer(1000).difference(geom.buffer(-1000))\n",
    "    large_buffer = geom.buffer(5000).difference(geom.buffer(-5000))\n",
    "    large_ring = large_buffer.difference(small_ring)\n",
    "    \n",
    "    base_props = {\n",
    "        'WDPA_PID': park['WDPA_PID'],\n",
    "        'ORIG_NAME': park['ORIG_NAME'],\n",
    "        'GOV_TYPE': park['GOV_TYPE'],\n",
    "        'OWN_TYPE': park['OWN_TYPE'],\n",
    "        'STATUS_YR': park['STATUS_YR'],\n",
    "        'IUCN_CAT': park['IUCN_CAT'],\n",
    "        'GIS_AREA': park['GIS_AREA'],\n",
    "        'PA_RATIO': park['PA_RATIO'],\n",
    "        'BIOME_NAME': park['BIOME_NAME']\n",
    "    }\n",
    "    \n",
    "    zones_list.extend([\n",
    "        {**base_props, 'zone': '1_km', 'geometry': small_ring},\n",
    "        {**base_props, 'zone': '5_km', 'geometry': large_ring}\n",
    "    ])\n",
    "\n",
    "zones_gdf = gpd.GeoDataFrame(zones_list, crs=gdf.crs)\n",
    "zones_gdf.to_file('/workspace/data/zones/zones.shp', driver='ESRI Shapefile')\n",
    "#ADD EXPORT TO ASSETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d6a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = ee.FeatureCollection('projects/dse-staff/assets/zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfacbb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_masked = HM_IMAGE.updateMask(WATER_MASK)\n",
    "\n",
    "hm_results = hm_masked.reduceRegions(\n",
    "    collection=zones,\n",
    "    reducer=ee.Reducer.mean().combine(ee.Reducer.stdDev(), '', True)\n",
    "        .setOutputs(['hm_mean', 'hm_stddev']),\n",
    "    scale=500,\n",
    "    tileScale=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process multiple years of MODIS gradient data with task queue management\n",
    "import time\n",
    "\n",
    "years = list(range(2001, 2024))  # 2001 to 2023\n",
    "max_concurrent_tasks = 10\n",
    "submitted_tasks = []\n",
    "\n",
    "def check_task_status():\n",
    "    \"\"\"Check status of submitted tasks and remove completed ones\"\"\"\n",
    "    global submitted_tasks\n",
    "    active_tasks = []\n",
    "    for task_obj, year in submitted_tasks:\n",
    "        task_status = task_obj.status()\n",
    "        if task_status['state'] in ['COMPLETED', 'FAILED', 'CANCELLED']:\n",
    "            print(f\"Task {year} {task_status['state']}\")\n",
    "        else:\n",
    "            active_tasks.append((task_obj, year))\n",
    "    submitted_tasks = active_tasks\n",
    "    return len(submitted_tasks)\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    # Wait if we have too many active tasks\n",
    "    while check_task_status() >= max_concurrent_tasks:\n",
    "        print(f\"Waiting... {len(submitted_tasks)} tasks active\")\n",
    "        time.sleep(30)  # Check every 30 seconds\n",
    "    \n",
    "    print(f\"Processing year {year} ({i+1}/{len(years)})...\")\n",
    "    \n",
    "    # Get MODIS and calculate NDVI\n",
    "    modis = MODIS.filterDate(f'{year}-01-01', f'{year}-12-31') \\\n",
    "        .median() \\\n",
    "        .select(['sur_refl_b01', 'sur_refl_b02'])  # Red and NIR bands\n",
    "    \n",
    "    # Calculate NDVI\n",
    "    ndvi = modis.normalizedDifference(['sur_refl_b02', 'sur_refl_b01']).rename('ndvi').select('ndvi')\n",
    "    \n",
    "    # Calculate gradient of NDVI\n",
    "    grad = ndvi.gradient()\n",
    "    magnitude = grad.expression('sqrt(x*x + y*y)', {'x': grad.select('x'), 'y': grad.select('y')}).rename('gradient_magnitude')\n",
    "    magnitude_masked = magnitude.updateMask(WATER_MASK)\n",
    "\n",
    "    # Reduce with explicit CRS and scale matching MODIS\n",
    "    final_results = magnitude_masked.reduceRegions(\n",
    "        collection=hm_results,\n",
    "        reducer=ee.Reducer.mean().combine(ee.Reducer.stdDev(), '', True)\n",
    "            .setOutputs(['gradient_mean', 'gradient_stddev']),\n",
    "        scale=500,  \n",
    "        tileScale=8\n",
    "    )\n",
    "    \n",
    "    # Export results and track task\n",
    "    export_task = ee.batch.Export.table.toCloudStorage(\n",
    "        collection=final_results,\n",
    "        description=f'results_{year}',\n",
    "        bucket='dse-staff',\n",
    "        fileNamePrefix=f'protected_areas/results2/results_{year}',\n",
    "        fileFormat='CSV',\n",
    "        selectors=['WDPA_PID', 'ORIG_NAME', 'GOV_TYPE', 'OWN_TYPE',\n",
    "                   'STATUS_YR', 'IUCN_CAT', 'GIS_AREA', 'PA_RATIO', 'BIOME_NAME',\n",
    "                   'zone', 'hm_mean', 'hm_stddev', 'gradient_mean', 'gradient_stddev']\n",
    "    )\n",
    "    export_task.start()\n",
    "    submitted_tasks.append((export_task, year))\n",
    "    print(f\"Export task started: {export_task.id} for {year}\")\n",
    "\n",
    "# Wait for remaining tasks to complete\n",
    "print(\"Waiting for remaining tasks to complete...\")\n",
    "while check_task_status() > 0:\n",
    "    print(f\"Still waiting for {len(submitted_tasks)} tasks...\")\n",
    "    time.sleep(30)\n",
    "\n",
    "print(\"All export tasks completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified version - just use gsutil and handle errors better\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simple download with error handling\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "try:\n",
    "    result = subprocess.run(['gsutil', 'ls', 'gs://dse-staff/protected_areas/results/*.csv'], \n",
    "                          capture_output=True, text=True, check=True)\n",
    "    files = result.stdout.strip().split('\\n')\n",
    "    print(f\"Found {len(files)} files\")\n",
    "    \n",
    "    # Download all files\n",
    "    subprocess.run(['gsutil', '-m', 'cp'] + files + [temp_dir], check=True)\n",
    "    \n",
    "    # Load and combine\n",
    "    all_data = []\n",
    "    for file in glob.glob(os.path.join(temp_dir, '*.csv')):\n",
    "        year = int(os.path.basename(file).split('_')[-1].split('.')[0])\n",
    "        df = pd.read_csv(file)\n",
    "        df['year'] = year\n",
    "        all_data.append(df)\n",
    "    \n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    combined_df['pid_zone'] = combined_df['WDPA_PID'].astype(str) + '_' + combined_df['zone']\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for pid_zone in combined_df['pid_zone'].unique():\n",
    "        subset = combined_df[combined_df['pid_zone'] == pid_zone].sort_values('year')\n",
    "        plt.plot(subset['year'], subset['gradient_mean'], alpha=0.7, linewidth=1)\n",
    "    \n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('NDVI Gradient Mean')\n",
    "    plt.title('Timeline of NDVI Gradient by Protected Area and Buffer Zone')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Maybe no files exist yet or gsutil auth issue\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
