{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203e1689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project='dse-staff')\n",
    "\n",
    "# Configuration\n",
    "modis = ee.ImageCollection('MODIS/061/MOD13A1') # MODIS NDVI Collection\n",
    "modis2 = ee.ImageCollection('MODIS/061/MOD09GA') # MODIS Surface Reflectance Collection (NDBI)\n",
    "gsw = ee.Image('JRC/GSW1_4/GlobalSurfaceWater')\n",
    "hm = ee.ImageCollection('CSP/HM/GlobalHumanModification').mean()\n",
    "elevation = ee.Image('USGS/SRTMGL1_003').select('elevation')\n",
    "slope = ee.Terrain.slope(elevation)\n",
    "folder_name = f\"boundary-project_results_{datetime.now().strftime('%Y%m%d')}\"\n",
    "print(f\"All results will be saved to Google Drive folder: {folder_name}\")\n",
    "\n",
    "staticImage = ee.Image.cat([\n",
    "    gsw.select('max_extent'),\n",
    "    hm.rename('gHM'),\n",
    "    elevation,\n",
    "    slope\n",
    "])\n",
    "\n",
    "years = ee.List.sequence(2001, 2021)\n",
    "gradBandNames = [str(y) for y in range(2001, 2022)]\n",
    "selectors = ['WDPA_PID', 'transectID', 'pointID', 'max_extent', 'gHM', 'elevation', 'slope'] + gradBandNames\n",
    "\n",
    "# More efficient masking - combine into single mask\n",
    "def mask_mod09ga_light(img):\n",
    "    qa = img.select('state_1km')\n",
    "    # Combine all masks before applying\n",
    "    mask = (qa.bitwiseAnd(3).eq(0)           # clear\n",
    "            .And(qa.bitwiseAnd(1 << 2).eq(0))  # no shadow\n",
    "            .And(qa.bitwiseAnd(1 << 12).eq(0))) # no snow\n",
    "    return (img\n",
    "        .updateMask(mask)\n",
    "        .select(['sur_refl_b02', 'sur_refl_b06'])\n",
    "        .multiply(0.0001)\n",
    "    )\n",
    "\n",
    "# Pre-filter before mapping to reduce processing\n",
    "def make_ndbi_gradient(y):\n",
    "    annual = (modis2\n",
    "        .filter(ee.Filter.calendarRange(y, y, 'year'))  # Filter FIRST\n",
    "        .map(mask_mod09ga_light)\n",
    "        .median())\n",
    "    ndbi = annual.normalizedDifference(['sur_refl_b06', 'sur_refl_b02']).rename('NDBI')\n",
    "    grad = ndbi.gradient()\n",
    "    grad_mag = grad.select('x').hypot(grad.select('y')).unmask(-9999)\n",
    "    return grad_mag.rename(['grad'])\n",
    "\n",
    "def make_gradient(y):\n",
    "    ndvi = modis.filter(ee.Filter.calendarRange(y, y, 'year')).select('NDVI').median()\n",
    "    grad = ndvi.gradient()\n",
    "    grad_mag = grad.select('x').hypot(grad.select('y')).unmask(-9999)\n",
    "    return grad_mag.rename(['grad'])\n",
    "\n",
    "gradientBands = ee.ImageCollection.fromImages(\n",
    "    years.map(make_ndbi_gradient)\n",
    ").toBands()\n",
    "gradientBands = gradientBands.rename(gradBandNames)\n",
    "image = staticImage.addBands(gradientBands)\n",
    "\n",
    "def process_samples(asset_path, chunk_size=50_000, batch_size=10):\n",
    "    samples = ee.FeatureCollection(asset_path)\n",
    "    size = samples.size().getInfo()\n",
    "    nChunks = int((size + chunk_size - 1) // chunk_size)\n",
    "    tasks = []\n",
    "\n",
    "    for i in range(nChunks):\n",
    "        fcChunk = ee.FeatureCollection(samples.toList(chunk_size, i * chunk_size))\n",
    "        sampled = image.reduceRegions(\n",
    "            collection=fcChunk,\n",
    "            reducer=ee.Reducer.first(),\n",
    "            scale=500\n",
    "        )\n",
    "        task = ee.batch.Export.table.toDrive(\n",
    "            collection=sampled,\n",
    "            description=f'ndbi_grad_{asset_path.split(\"_\")[-1]}_chunk_{i}',\n",
    "            fileFormat='CSV',\n",
    "            selectors=selectors, \n",
    "            folder=folder_name\n",
    "        )\n",
    "        tasks.append(task)\n",
    "\n",
    "    for j in range(0, len(tasks), batch_size):\n",
    "        batch = tasks[j:j + batch_size]\n",
    "        for t in batch:\n",
    "            t.start()\n",
    "        \n",
    "        batch_start = j + 1\n",
    "        batch_end = min(j + batch_size, nChunks)\n",
    "        print(f\"  Processing chunks {batch_start}-{batch_end} of {nChunks}...\")\n",
    "        \n",
    "        while True:\n",
    "            statuses = [t.status()['state'] for t in batch]\n",
    "            if all(s in ['COMPLETED', 'FAILED', 'CANCELLED'] for s in statuses):\n",
    "                print(f\"  Completed chunks {batch_start}-{batch_end} of {nChunks}\")\n",
    "                break\n",
    "            time.sleep(30)\n",
    "\n",
    "# Sequentially process each asset from 000 to 009\n",
    "total_assets = 10\n",
    "for idx in range(total_assets):\n",
    "    asset = f'projects/dse-staff/assets/chunk_{idx:03d}'\n",
    "    print(f\"\\nProcessing asset {idx + 1} of {total_assets}: {asset}\")\n",
    "    process_samples(asset)\n",
    "    print(f\"Asset {idx + 1} of {total_assets} complete\")\n",
    "\n",
    "print(f\"\\nAll {total_assets} assets processed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
